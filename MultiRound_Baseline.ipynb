{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "eSCMzyxlbbA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1iU4ezzR9S-",
        "outputId": "f2154405-841d-48eb-81aa-5f38ef491034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nja8QgWDT7wa",
        "outputId": "5fd2de17-39ca-43f6-ae51-c261a21aea4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: surprise in /usr/local/lib/python3.8/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.8/dist-packages (from surprise) (1.1.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from IPython.display import display\n",
        "from surprise import Dataset\n",
        "from surprise import KNNBasic\n",
        "from surprise import Reader"
      ],
      "metadata": {
        "id": "UaXd_CNsJ7Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing Parameters"
      ],
      "metadata": {
        "id": "HiFPBJmObgRF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNidF7XPIIpx"
      },
      "outputs": [],
      "source": [
        "mu= 4.6818430002382145\n",
        "rating = pd.read_csv(\"/content/drive/MyDrive/RS Data/Assignment 2/Baseline/Train_data.csv\") # Empty Rating Matrix\n",
        "bi =np.load(\"/content/drive/MyDrive/RS Data/Assignment 2/Baseline/bi.npy\")\n",
        "bu =np.load(\"/content/drive/MyDrive/RS Data/Assignment 2/Baseline/bi.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/RS Data/Assignment 2/Baseline/recipe_names.pkl', 'rb') as fp:\n",
        "    names = pickle.load(fp)\n",
        "    print('Recipe_Name dictionary imported successfully')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TXiJYpVIbBy",
        "outputId": "3dc52a8f-61ae-4db0-e807-5f1450492df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recipe_Name dictionary imported successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Round Recommendation System (Baseline Estimate)"
      ],
      "metadata": {
        "id": "iswqeTGTbmQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Multi_RecSys():\n",
        "  def __init__(self,train,mu,bi,bu,names):\n",
        "    self.train = train\n",
        "    self.mu = mu\n",
        "    self.bi = bi\n",
        "    self.bu = bu\n",
        "    self.R_ = self.mu + np.dot(self.bu,self.bi.T)\n",
        "    self.dct = {user_id: index for index, user_id in enumerate(self.train.index)}\n",
        "    self.rec_name = names\n",
        "  \n",
        "  def BaseLine(self):\n",
        "\n",
        "    user_id = int(input(\"Enter Your User Id:  \"))\n",
        "    os.system('cls')\n",
        "    print(\"\\n\\n\")\n",
        "    \n",
        "    print(f\"Welcome User {user_id}\")\n",
        "    print(\"\\n\\n\")\n",
        "    \n",
        "    uid = self.dct[user_id]\n",
        "    unrated_items = np.where(self.train.iloc[uid, :] == 0)[0]\n",
        "\n",
        "    # Sort the predicted ratings for unrated items in descending order\n",
        "    sorted_ratings = np.argsort(self.R_[uid, unrated_items])[::-1]\n",
        "\n",
        "    # Recommend the top N items to the user\n",
        "    N = 5\n",
        "    recommended_items = unrated_items[sorted_ratings][:N]\n",
        "    print(f\" We have these recommendations for you today: \\n \")\n",
        "    new_dict = {}\n",
        "    for idx in recommended_items:\n",
        "      key = list(self.rec_name.keys())[idx]\n",
        "      value = self.rec_name[key]\n",
        "      new_dict[key] = value\n",
        "\n",
        "    output_df = pd.DataFrame.from_dict(new_dict, orient='index', columns=['Recpie_Name'])\n",
        "    output_df = output_df.rename_axis('Recipe_ID')\n",
        "    display(output_df)\n",
        "    return recommended_items\n",
        "\n",
        "  def get_recommendations(self):\n",
        "    print(\"This system works on Baseline Estimated Recommendation System\")\n",
        "    self.BaseLine()\n",
        "\n",
        "  def KNN(self):\n",
        "    reader = Reader(rating_scale=(0, 5))\n",
        "    data = Dataset.load_from_df(pd.DataFrame(self.train), reader)\n",
        "    sim_options = {'name': 'cosine', 'user_based': False}\n",
        "    k = 3\n",
        "    model = KNNBasic(k=k, sim_options=sim_options)\n",
        "    trainset = data.build_full_trainset()\n",
        "    model.fit(trainset)\n",
        "    item_similarity_matrix = model.compute_similarities()\n",
        "    return item_similarity_matrix,model,trainset\n",
        "\n",
        "  def multi_round(self,file_path):\n",
        "    rounds=1\n",
        "    while rounds != 10:\n",
        "      if rounds == 1:\n",
        "        self.get_recommendations()\n",
        "        cnt = int(input(\"Do you want further recommendations? (1/0)  \"))\n",
        "        if cnt == 0:\n",
        "          inp = int(input(\"Give us the recipe_id that you like: \"))\n",
        "          print(\"info\")\n",
        "          break\n",
        "        \n",
        "      else:\n",
        "        if rounds == 2:\n",
        "          item_similarity_matrix,model,trainset = self.KNN(file_path)\n",
        "        inp = int(input(\"Give us the recipe_id that you prefer: \"))\n",
        "        # Rank items based on similarity to item of interest\n",
        "        item_of_interest = str(inp)\n",
        "        item_id = model.trainset.to_inner_iid(item_of_interest)\n",
        "        similar_items = model.get_neighbors(item_id, k=k+1)\n",
        "\n",
        "        # Choose a similarity threshold\n",
        "        similarity_threshold = 0.5\n",
        "\n",
        "        # Recommend items based on similarity and user's previous ratings\n",
        "        recommended_items = [model.trainset.to_raw_iid(item) for item in similar_items if item != item_id and item_similarity_matrix[item_id, item] >= similarity_threshold and trainset.ur[trainset.to_inner_iid('user1')] == 0]\n",
        "        print(\"\\n\")\n",
        "        print(recommended_items)\n",
        "        print(\"\\n \\n\")\n",
        "        cnt = int(input(\"Do you want further recommendations? (1/0)  \"))\n",
        "        if cnt == 0:\n",
        "          inp = int(input(\"Give us the recipe_id that you like: \"))\n",
        "          print(\"info\")\n",
        "          break\n",
        "        \n",
        "      rounds+=1"
      ],
      "metadata": {
        "id": "LrNqPPfmIWa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MRR=Multi_RecSys(rating,mu,bi,bu,names)\n",
        "MRR.multiround()"
      ],
      "metadata": {
        "id": "Z6nJYaOlUM0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: This approach requries a bit more ram due to which it crashes sometimes on collab otherwise it works well."
      ],
      "metadata": {
        "id": "Mix70xpDb80b"
      }
    }
  ]
}